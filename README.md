# Judging a Book by its Cover
## An MSiA AVC Final Project
---
## Team
**Lead Developer** : Nathan Franklin  
**Lead QA** : Tony Colucci  
**Faculty Advisors** : Chloe Mawer & Fausto Inestroza  

## Project Charter

**Vision:** 
A potential reader of a piece of prose - whether an article, a novel, a blog post, or something else - cannot know the contents of that piece without actually reading it. Thus they cannot know if they will enjoy its contents until they have already consumed them. The human heuristic to solve this problem is to make a judgment call based on the observable characteristics of a text. In effect, humans must 'judge a book by its cover', as well as by other features we will collectively label 'meta details' (genre, title, reviews, length, etc...). Thus, it is extremely important for the people who make these decisions about a piece of writing to provide potential readers with meta details which most accurately convey the contents of the piece. This project exists to ease some of this burden by using machine learning to give suggestions to the authors, editors, publishers, or other decision makers involved in this proccess.

**Mission:** 
The goal of this project is to give suggestions for meta data based on a user's input. In this project, the model will generate these suggestions based on a user-provided summary of the larger prose piece in question. These suggestions will hopefully be informative and useful for those making these decisions, allowing them to more accurately represent their text to readers.

**Success Criteria:** 
* Model Performance: Genre classification accuracy of >= 75% 
* Business Performance:  Users consider meta detail suggestions to be helpful and to accurately convey information about the larger piece >= 50% of the time.

## Repo Structure

```
├── README.md                         <- Welcome. You are here.
├── environment.yml                   <- Requirements for a conda environment
├── requirements.txt                  <- Requirements for a virtual environment
├── planning.md                       <- To-do's, Backlog, and icebox
├── makefile                          <- Makefile to construct everything necessary for final app to run from just a newly cloned repository.
│
├── app/                              <- Directory with .py files and others for flask web app to run
│   ├── static/                       <- CSS and other static files for web app 
│       ├── images/                   <- Images generated by the web app, stored here and displayed in the app
│   ├── templates/                    <- HTML for web app display
│   ├── app.py                        <- Main web app skeleton
│   ├── database_interaction.py       <- Helper functions for establishing database connections and adding to database
│   ├── plot_results.py               <- Helper function to plot results of RFC model
│
├── config/                           <- Directory for configuration files for logging, model parameters, etc...
│   ├── config.yml                    <- Configuration file for app: model training, scoring, database info, etc...
│   ├── flask_config.yml              <- Configuration file for Flask app
│   ├── logging_local.conf            <- Configuration file for local loggers
│   ├── mysql_config.yml              <- Configuration file for database connections
│   ├── src_config.yml                <- Configuration file for src folder files
│
├── data/                             <- Folder that contains data used or generated. 
│   ├── booksummaries/                <- Storage repository for project's main data, not synced with git
│   ├── names/                        <- Storage repository for some name data
│
├── models/                           <- Trained model objects (TMOs), model predictions, and/or model summaries
│
├── notebooks/
│   ├── develop/                      <- Current notebooks being used in development.
│   ├── archive/                      <- Develop notebooks no longer being used.
│   ├── demonstration/                <- Template notebooks for analysis with useful imports and helper functions. 
│
├── src/                              <- Source data for the project 
│   ├── helpers/                      <- Helper scripts used in main src files 
│   ├── 1-get_data.py                 <- Script for getting data from source and storing locally or in AWS S3 bucket
│   ├── 2-clean_genres.py             <- Script to consolidate genres
│   ├── 3-clean_summaries_gen_vecs.py <- Script to clean summaries and generate word2vec sentence vectors
│   ├── 4-gen_LDA_model.py            <- Script to generate LDA model from our data
│   ├── 5-gen_LDA_vecs.py             <- Script to generate vectors with our LDA models
│   ├── 6-train_model.py              <- Script to train an RFC model from our data set
│
├── test/                             <- Files necessary for running model tests (see documentation below) 
```
This project structure was partially influenced by the [Cookiecutter Data Science project](https://drivendata.github.io/cookiecutter-data-science/).

## Setup

### 1.) Set Up Your Environment (conda or virtual env)

#### Conda

Create and activate a conda environment using the `environment.yml` file found in the root directory.  
```bash
conda env create environment.yml
```

#### Virtual Env

Create and activate a virtual environment using the `requirements.txt` file found in the root directory.    
```bash
virtualenv example_env
source example_env/bin/activate
pip install -r requirements.txt
```

### 2.) Configure The Necessary Settings in `config/`
#### mysql_config.yml
Decide where you want your database to live. If locally, in a sqlite database, simply set
```yaml
USE_RDS: False
```
and you needn't worry about the rest.

If you wish to use RDS, change
```yaml
USE_RDS: True
```
and then
```yaml
MYSQL_USER: 
MYSQL_HOST: 
MYSQL_PORT: 
DB_NAME: 
```
to reflect your own RDS instance and settings. At this point it is also necessary to set your `MYSQL_PASSWORD`. Do this from your terminal with a command similar to the following.
```bash
export MYSQL_PASSWORD=example_password
```
#### src_config.yml
The only thing to change here is whether or not to store the raw data, data artifacts, and models in both local and S3 or only on local. To incorporate S3, at the top of the file, find and set these lines as wanted:
``` yaml
src:
    s3:
        use: False
        bucket_name: example_bucket_name
```
You can change `use` to `True` and `bucket_name` to a bucket you've created previously.

#### AWS CLI
If you intend to use RDS or S3, you must have AWS CLI [installed](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html) & [configured](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html)

### 3.) Obtaining/Cleaning Data, Generating Features, and Training a Model
If all previous steps have been completed, simply running
``` bash
make all
```
from the root directory in a bash terminal will enact a sequence of events which downloads the data -> cleans/consolidates the genre column -> cleans summaries and generates word2vec features -> trains an LDA model -> applies the LDA model to get more features -> trains a multi-label Random Forest Classifier Model.

This process should take somwhere ~5-10 minutes.

### 4.) Running the Web App
From here, navigate to the `app/` directory, and run 
```bash
python app.py
```
This will start your web server with the app running.

### 5.) Finding Database Entries
You may want to check that user interactions are being stored in your database. To do so, if you did not use RDS and stored locally, in the `data/` folder there will be a `.db` file with your data.

If you used RDS, go to a machine with MySQL command line tools installed or install them on your own. Connect to your RDS instance using the following:
``` bash
$ mysql -u <RDS-username> -p -h <RDS-endpoint>
```
After providing the password used to create your RDS instance, you can use the following commands to ensure your MySQL instantiation worked. 
```
mysql> show databases;
mysql> use my_example_table;
mysql> show tables;
```

## Other
* **Data Source:** [CMU Book Summary Dataset](http://www.cs.cmu.edu/~dbamman/booksummaries.html)








