{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import sys; sys.path.append('../../src/helpers')\n",
    "from data_manipulation import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('../../data/booksummaries/books_Porter_True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookGenre</th>\n",
       "      <th>plotSum</th>\n",
       "      <th>bookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['roman_à_clef', 'satire', 'childrens_literatu...</td>\n",
       "      <td>old old boar manor farm call anim farm meet co...</td>\n",
       "      <td>Animal Farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['science_fiction', 'novella', 'speculative_fi...</td>\n",
       "      <td>teenag live nearfutur england lead gang nightl...</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['existentialism', 'fiction', 'absurdist_ficti...</td>\n",
       "      <td>text plagu divid five part town oran thousand ...</td>\n",
       "      <td>The Plague</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           bookGenre  \\\n",
       "0  ['roman_à_clef', 'satire', 'childrens_literatu...   \n",
       "1  ['science_fiction', 'novella', 'speculative_fi...   \n",
       "2  ['existentialism', 'fiction', 'absurdist_ficti...   \n",
       "\n",
       "                                             plotSum           bookTitle  \n",
       "0  old old boar manor farm call anim farm meet co...         Animal Farm  \n",
       "1  teenag live nearfutur england lead gang nightl...  A Clockwork Orange  \n",
       "2  text plagu divid five part town oran thousand ...          The Plague  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12841,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = books.iloc[:,1]\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our documents into BOW style.\n",
    "tf_vectorizer = CountVectorizer(max_df=0.90, max_features=1000)\n",
    "tf = tf_vectorizer.fit_transform(corpus)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['34', '39', 'abandon']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_feature_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12841, 1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/AVC/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=8, perp_tol=0.1,\n",
       "             random_state=123, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=8, max_iter=5, learning_method='online', learning_offset=50.,random_state=123)\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic: \"+ str(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      "find kill one return power take help magic escap use attack back citi two way name leav dragon howev fight\n",
      "Topic: 1\n",
      "kill war forc attack ship offic order take armi plan state agent captain command use unit escap new attempt one\n",
      "Topic: 2\n",
      "mr return marri murder wife love de visit man hous take young sir letter father meet ladi leav arriv son\n",
      "Topic: 3\n",
      "human earth ship planet time world one alien space use year destroy race new system doctor discov find travel technolog\n",
      "Topic: 4\n",
      "famili father mother life becom love live year children son begin friend young new daughter child girl home die stori\n",
      "Topic: 5\n",
      "book novel stori charact first also life narrat one time chapter end work includ describ new set world part begin\n",
      "Topic: 6\n",
      "find get tell go one back day hous take see leav come tri say call friend meet make time goe\n",
      "Topic: 7\n",
      "peopl would one world tom wolf use also even human power make time way work state like could chang need\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, tf_feature_names, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['''the magic man once gave me 100 dollars and then the dragon came and\n",
    "                swept me magically with magic off to the swords sword wizard''', \n",
    "         '''my best friend had my back growing up and my family was always \n",
    "             there and i loved love them''']\n",
    "\n",
    "X_test = tf_vectorizer.transform(corpus)\n",
    "doc_topic_dist_unnormalized = np.matrix(lda.transform(X_test))\n",
    "\n",
    "# normalize the distribution (only needed if you want to work with the probabilities)\n",
    "doc_topic_dist = doc_topic_dist_unnormalized/doc_topic_dist_unnormalized.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.8905413 , 0.01562893, 0.01564237, 0.01563046, 0.01563336,\n",
       "         0.01563696, 0.01564651, 0.01564011],\n",
       "        [0.02505473, 0.02502553, 0.02503071, 0.02502919, 0.82473257,\n",
       "         0.02501223, 0.0250976 , 0.02501744]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_dist_unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.8905413 , 0.01562893, 0.01564237, 0.01563046, 0.01563336,\n",
       "         0.01563696, 0.01564651, 0.01564011],\n",
       "        [0.02505473, 0.02502553, 0.02503071, 0.02502919, 0.82473257,\n",
       "         0.02501223, 0.0250976 , 0.02501744]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now you've gotten it to where you've \"found\" topics based on your big corpus, by training your count_vectorizer and LDA model on the original big corpus, and then by entering new text you can get apply the same vectorization transform to them and then get an LDA score for each sentence in terms of the topics you've already found!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AVC",
   "language": "python",
   "name": "avc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
